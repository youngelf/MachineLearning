{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Notes\n",
    "\n",
    "\n",
    "## Jupyter notes\n",
    "To attach to an existing python kernel, you run this command at the console:\n",
    "```\n",
    "$ jupyter console --existing\n",
    "```\n",
    "But then, when you exit, the kernel stops! This is probably not what you want. So exit like this:\n",
    "```\n",
    "exit(keep_kernel=True)\n",
    "```\n",
    "Ctrl-D also works, it asks if you want to keep the kernel alive, and it does as asked\n",
    "\n",
    "\n",
    "To get information about the kernel, you run the following pragma in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 45977,\n",
      "  \"iopub_port\": 49741,\n",
      "  \"stdin_port\": 33997,\n",
      "  \"control_port\": 45215,\n",
      "  \"hb_port\": 33623,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"2a788679-908fa47b81655e5a37c3b625\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-45b0e02a-94d2-4cac-8ca4-c1076bd666ee.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter is modal (yay, vi gets the last laugh) and supports a lot of commands in the command-mode. Here are some of them that I found useful\n",
    "\n",
    " * Esc: Go to command mode.\n",
    " * *p*: Show the command (P)rompt, where you can type the name of a command (not all commands are mapped to keystrokes)\n",
    " * *m*: Change cell to (M)arkup mode.\n",
    " * *y*: Change cell to code or P(Y)thon mode.\n",
    " * *a/b*: Add cell (A)bove/add cell (B)elow\n",
    " * *Shift-O*: Toggle scr(O)lling for the output, so you can expand the full output.\n",
    " * Enter: Go to edit mode\n",
    " * *j*/*k*: Usual vi down/up movement.\n",
    " * *h*: Show (H)elp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Interesting machine learning models.\n",
    "\n",
    "Read about [GPT-3](https://www.jesuisundev.com/en/gpt-3-the-gigantic-artificial-intelligence/). Much more [information about GPT-3](https://www.gwern.net/GPT-3#william-shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music based learning\n",
    "\n",
    "Links for either training based on music, extracing music features or generating music\n",
    "\n",
    "[Extracting music features](https://towardsdatascience.com/extract-features-of-music-75a3f9bc265d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web data based learning\n",
    "\n",
    "[Getting stock information](https://medium.com/@andy.m9627/the-ultimate-guide-to-stock-market-apis-for-2020-1de6f55adbb) and [this company](https://finnhub.io/) has a great free product for getting open/high/low/close information over a time period.\n",
    "[Scraping the web for arbitrary information](https://github.com/alirezamika/autoscraper)\n",
    "\n",
    "\n",
    "[An example of using Yahoo's stock api](https://github.com/sombandy/stock-market/blob/master/stock_performance.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git notes\n",
    "\n",
    "This is how you configure git\n",
    "```\n",
    "git config --global credential.helper cache\n",
    "git config --global credential.helper 'cache --timeout=9999999999'\n",
    "git config --global user.email \"vikram@eggwall.com\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance in dimension 1 is 0.333250\n",
      "Mean distance in dimension 2 is 0.521256\n",
      "Mean distance in dimension 3 is 0.661650\n",
      "Mean distance in dimension 4 is 0.777662\n",
      "Mean distance in dimension 10 is 1.267396\n",
      "Mean distance in dimension 100 is 4.075047\n",
      "Mean distance in dimension 1000 is 12.907584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Run later\n",
    "d={}\n",
    "runs = 1000000\n",
    "\n",
    "for dimensions in (1, 2, 3, 4, 10, 100, 1000, 1000000):\n",
    "    sum_distance = 0.0\n",
    "\n",
    "    for i in range(runs):\n",
    "        a=np.random.rand(dimensions)\n",
    "        b=np.random.rand(dimensions)\n",
    "        sum_distance += np.linalg.norm(a-b)\n",
    "    \n",
    "    sum_distance /= (1.0*runs)\n",
    "    print (\"Mean distance in dimension %d is %f\" % (dimensions, sum_distance))\n",
    "    d[str(dimensions)] = sum_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.3332496908264852,\n",
       " '2': 0.5212556131792213,\n",
       " '3': 0.6616503043959507,\n",
       " '4': 0.7776623425731862,\n",
       " '10': 1.2673959751112913,\n",
       " '100': 4.075047152565091,\n",
       " '1000': 12.907583942040752,\n",
       " '1000000': 408.24854896803464}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Testing that it exists, now that I've compiled it from source!\n",
    "\n",
    "And I needed to compile Tensorflow because pre-packaged binaries emit AVX instructions\n",
    "which my old machine doesn't support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version =  2.3.0\n",
      "Keras version =  2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version = \", tf.__version__)\n",
    "print(\"Keras version = \", tf.keras.__version__)\n",
    "\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.image import imread\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# import mpl_toolkits.mplot3d.axes3d as p3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print (X_train_full.shape)\n",
    "print (X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000]        , y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge TPU\n",
    "\n",
    "Edge TPU devices don't run full TensorFlow, they only run tflite. For this, we need to create tflite models rather than normal TF models.\n",
    "\n",
    "[This page talks about creating TFlite models](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb).  The [TFLite converter class](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) is the one that creates the converted model. Let's save our model so that we can practice with it later.\n",
    "\n",
    "I need to save the model, and then run a converter, and then load them up on the Edge TPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = 'fashion.h5'\n",
    "model.save(saved_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(saved_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('fashion_viki_test.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other notes\n",
    "Links for Google Cloud Courses\n",
    "[The single video](https://www.coursera.org/lecture/gcp-fundamentals/why-choose-google-cloud-platform-vXwU1)\n",
    "and the full course:\n",
    "[You have to select single courses to view the content for free](https://www.coursera.org/specializations/gcp-architecture?action=enroll&authType=google&completeMode=existingCourseraAccount#courses)\n",
    "\n",
    "[These are someone's notes on this exam](https://medium.com/@sathishvj/notes-from-my-google-cloud-professional-cloud-architect-exam-bbc4299ac30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notes\n",
    "\n",
    "Python is an interesting language, and the list/tuple/nparray takes a while getting used to. Here's some lessons from what I have picked up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocating large amounts of memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.array([40000, 100000, 10029100, 202002], dtype=np.float32)\n",
    "s=bytearray(51200000*100)\n",
    "s=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting help on a specific method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

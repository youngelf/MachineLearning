{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Notes\n",
    "\n",
    "\n",
    "## Jupyter notes\n",
    "To attach to an existing python kernel, you run this command at the console:\n",
    "```\n",
    "$ jupyter console --existing\n",
    "```\n",
    "But then, when you exit, the kernel stops! This is probably not what you want. So exit like this:\n",
    "```\n",
    "exit(keep_kernel=True)\n",
    "```\n",
    "Ctrl-D also works, it asks if you want to keep the kernel alive, and it does as asked\n",
    "\n",
    "\n",
    "To get information about the kernel, you run the following pragma in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 45977,\n",
      "  \"iopub_port\": 49741,\n",
      "  \"stdin_port\": 33997,\n",
      "  \"control_port\": 45215,\n",
      "  \"hb_port\": 33623,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"2a788679-908fa47b81655e5a37c3b625\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-45b0e02a-94d2-4cac-8ca4-c1076bd666ee.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter is modal (yay, vi gets the last laugh) and supports a lot of commands in the command-mode. Here are some of them that I found useful\n",
    "\n",
    " * Esc: Go to command mode.\n",
    " * *p*: Show the command (P)rompt, where you can type the name of a command (not all commands are mapped to keystrokes)\n",
    " * *m*: Change cell to (M)arkup mode.\n",
    " * *y*: Change cell to code or P(Y)thon mode.\n",
    " * *a/b*: Add cell (A)bove/add cell (B)elow\n",
    " * *Shift-O*: Toggle scr(O)lling for the output, so you can expand the full output.\n",
    " * Enter: Go to edit mode\n",
    " * *j*/*k*: Usual vi down/up movement.\n",
    " * *h*: Show (H)elp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Interesting machine learning models.\n",
    "\n",
    "Read about [GPT-3](https://www.jesuisundev.com/en/gpt-3-the-gigantic-artificial-intelligence/). Much more [information about GPT-3](https://www.gwern.net/GPT-3#william-shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music based learning\n",
    "\n",
    "Links for either training based on music, extracing music features or generating music\n",
    "\n",
    "[Extracting music features](https://towardsdatascience.com/extract-features-of-music-75a3f9bc265d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web data based learning\n",
    "\n",
    "[Getting stock information](https://medium.com/@andy.m9627/the-ultimate-guide-to-stock-market-apis-for-2020-1de6f55adbb) and [this company](https://finnhub.io/) has a great free product for getting open/high/low/close information over a time period.\n",
    "[Scraping the web for arbitrary information](https://github.com/alirezamika/autoscraper)\n",
    "\n",
    "\n",
    "[An example of using Yahoo's stock api](https://github.com/sombandy/stock-market/blob/master/stock_performance.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git notes\n",
    "\n",
    "This is how you configure git\n",
    "```\n",
    "git config --global credential.helper cache\n",
    "git config --global credential.helper 'cache --timeout=9999999999'\n",
    "git config --global user.email \"vikram@eggwall.com\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance in dimension 1 is 0.333250\n",
      "Mean distance in dimension 2 is 0.521256\n",
      "Mean distance in dimension 3 is 0.661650\n",
      "Mean distance in dimension 4 is 0.777662\n",
      "Mean distance in dimension 10 is 1.267396\n",
      "Mean distance in dimension 100 is 4.075047\n",
      "Mean distance in dimension 1000 is 12.907584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Run later\n",
    "d={}\n",
    "runs = 1000000\n",
    "\n",
    "for dimensions in (1, 2, 3, 4, 10, 100, 1000, 1000000):\n",
    "    sum_distance = 0.0\n",
    "\n",
    "    for i in range(runs):\n",
    "        a=np.random.rand(dimensions)\n",
    "        b=np.random.rand(dimensions)\n",
    "        sum_distance += np.linalg.norm(a-b)\n",
    "    \n",
    "    sum_distance /= (1.0*runs)\n",
    "    print (\"Mean distance in dimension %d is %f\" % (dimensions, sum_distance))\n",
    "    d[str(dimensions)] = sum_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.3332496908264852,\n",
       " '2': 0.5212556131792213,\n",
       " '3': 0.6616503043959507,\n",
       " '4': 0.7776623425731862,\n",
       " '10': 1.2673959751112913,\n",
       " '100': 4.075047152565091,\n",
       " '1000': 12.907583942040752,\n",
       " '1000000': 408.24854896803464}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Testing that it exists, now that I've compiled it from source!\n",
    "\n",
    "And I needed to compile Tensorflow because pre-packaged binaries emit AVX instructions\n",
    "which my old machine doesn't support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version =  2.3.0\n",
      "Keras version =  2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version = \", tf.__version__)\n",
    "print(\"Keras version = \", tf.keras.__version__)\n",
    "\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.image import imread\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# import mpl_toolkits.mplot3d.axes3d as p3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print (X_train_full.shape)\n",
    "print (X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000]        , y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge TPU\n",
    "\n",
    "Edge TPU devices don't run full TensorFlow, they only run tflite. For this, we need to create tflite models rather than normal TF models.\n",
    "\n",
    "[This page talks about creating TFlite models](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb).  The [TFLite converter class](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) is the one that creates the converted model. Let's save our model so that we can practice with it later.\n",
    "\n",
    "I need to save the model, and then run a converter, and then load them up on the Edge TPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphhyeosbg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphhyeosbg/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model = 'saved_models/fashion.h5'\n",
    "model.save(saved_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('saved_models/fashion_viki_test.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we need to convert the tflite models to edge TPU models. WTH, folks. This ought to be simpler than this. These instructions come from [the Coral page](https://coral.ai/docs/edgetpu/compiler/#system-requirements):\n",
    "\n",
    "```\n",
    "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get install edgetpu-compiler\n",
    "\n",
    "edgetpu-compiler model.tflite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, that doesn't work (were you expecting it to? You naive creature).\n",
    "\n",
    "For that, we have to quantize both the weights and the activation values. For that you have to [provide a representative dataset as this colab notebook points out](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb#scrollTo=w9ydAmHGHUZl&line=2&uniqifier=1). And of course, there [is some information on how to do this](https://www.tensorflow.org/lite/performance/post_training_quantization) but it is relatively slim on detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiujw_zaq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiujw_zaq/assets\n",
      "WARNING:absl:Please consider switching to the new converter by setting experimental_new_converter=True. The old converter (TOCO) is deprecated.\n"
     ]
    }
   ],
   "source": [
    "saved_model = 'saved_models/fashion.h5'\n",
    "model.save(saved_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "def representative_dataset_gen():\n",
    "    num_calibration_steps = 5\n",
    "    for p in range(num_calibration_steps):\n",
    "        # Get sample input data as a numpy array in a method of your choosing.\n",
    "        sample = X_train[p]\n",
    "        sample = tf.cast(sample, tf.float32)\n",
    "        yield [sample]\n",
    "\n",
    "\n",
    "# Set the representative dataset for the converter so we can quantize the activations\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "# Turn off MLIR\n",
    "converter.experimental_new_converter = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('saved_models/fashion_viki_test.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good lord. This is messy beyond belief. The [edgetpu-compiler itself crashes sometimes](https://github.com/google-coral/edgetpu/issues/168). No useful error messages, no information on how to provide it input, what format it is looking for. How the hell do people develop for this?\n",
    "\n",
    "[Someone else's view on how to get it working](https://towardsdatascience.com/solutions-to-issues-with-edge-tpu-32374310e732). This thing is a certified loony-town."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other notes\n",
    "Links for Google Cloud Courses\n",
    "[The single video](https://www.coursera.org/lecture/gcp-fundamentals/why-choose-google-cloud-platform-vXwU1)\n",
    "and the full course:\n",
    "[You have to select single courses to view the content for free](https://www.coursera.org/specializations/gcp-architecture?action=enroll&authType=google&completeMode=existingCourseraAccount#courses)\n",
    "\n",
    "[These are someone's notes on this exam](https://medium.com/@sathishvj/notes-from-my-google-cloud-professional-cloud-architect-exam-bbc4299ac30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notes\n",
    "\n",
    "Python is an interesting language, and the list/tuple/nparray takes a while getting used to. Here's some lessons from what I have picked up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocating large amounts of memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.array([40000, 100000, 10029100, 202002], dtype=np.float32)\n",
    "s=bytearray(51200000*100)\n",
    "s=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting help on a specific method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

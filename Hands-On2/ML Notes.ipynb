{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Notes\n",
    "\n",
    "\n",
    "## Jupyter notes\n",
    "To attach to an existing python kernel, you run this command at the console:\n",
    "```\n",
    "$ jupyter console --existing\n",
    "```\n",
    "But then, when you exit, the kernel stops! This is probably not what you want. So exit like this:\n",
    "```\n",
    "exit(keep_kernel=True)\n",
    "```\n",
    "Ctrl-D also works, it asks if you want to keep the kernel alive, and it does as asked\n",
    "\n",
    "\n",
    "To get information about the kernel, you run the following pragma in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 42297,\n",
      "  \"iopub_port\": 58367,\n",
      "  \"stdin_port\": 40507,\n",
      "  \"control_port\": 50409,\n",
      "  \"hb_port\": 51533,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"ca16488c-9b63e74752a90ba815b410e2\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-bb588930-22bd-44d0-9753-aa255fc758fd.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter is modal (yay, vi gets the last laugh) and supports a lot of commands in the command-mode. Here are some of them that I found useful\n",
    "\n",
    " * Esc: Go to command mode.\n",
    " * *p*: Show the command (P)rompt, where you can type the name of a command (not all commands are mapped to keystrokes)\n",
    " * *m*: Change cell to (M)arkup mode.\n",
    " * *y*: Change cell to code or P(Y)thon mode.\n",
    " * *a/b*: Add cell (A)bove/add cell (B)elow\n",
    " * *Shift-O*: Toggle scr(O)lling for the output, so you can expand the full output.\n",
    " * Enter: Go to edit mode\n",
    " * *j*/*k*: Usual vi down/up movement.\n",
    " * *h*: Show (H)elp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Interesting machine learning models.\n",
    "\n",
    "Read about [GPT-3](https://www.jesuisundev.com/en/gpt-3-the-gigantic-artificial-intelligence/). Much more [information about GPT-3](https://www.gwern.net/GPT-3#william-shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music based learning\n",
    "\n",
    "Links for either training based on music, extracing music features or generating music\n",
    "\n",
    "[Extracting music features](https://towardsdatascience.com/extract-features-of-music-75a3f9bc265d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web data based learning\n",
    "\n",
    "[Getting stock information](https://medium.com/@andy.m9627/the-ultimate-guide-to-stock-market-apis-for-2020-1de6f55adbb) and [this company](https://finnhub.io/) has a great free product for getting open/high/low/close information over a time period.\n",
    "[Scraping the web for arbitrary information](https://github.com/alirezamika/autoscraper)\n",
    "\n",
    "\n",
    "[An example of using Yahoo's stock api](https://github.com/sombandy/stock-market/blob/master/stock_performance.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git notes\n",
    "\n",
    "This is how you configure git\n",
    "```\n",
    "git config --global credential.helper cache\n",
    "git config --global credential.helper 'cache --timeout=9999999999'\n",
    "git config --global user.email \"vikram@eggwall.com\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance in dimension 1 is 0.333250\n",
      "Mean distance in dimension 2 is 0.521256\n",
      "Mean distance in dimension 3 is 0.661650\n",
      "Mean distance in dimension 4 is 0.777662\n",
      "Mean distance in dimension 10 is 1.267396\n",
      "Mean distance in dimension 100 is 4.075047\n",
      "Mean distance in dimension 1000 is 12.907584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Run later\n",
    "d={}\n",
    "runs = 1000000\n",
    "\n",
    "for dimensions in (1, 2, 3, 4, 10, 100, 1000, 1000000):\n",
    "    sum_distance = 0.0\n",
    "\n",
    "    for i in range(runs):\n",
    "        a=np.random.rand(dimensions)\n",
    "        b=np.random.rand(dimensions)\n",
    "        sum_distance += np.linalg.norm(a-b)\n",
    "    \n",
    "    sum_distance /= (1.0*runs)\n",
    "    print (\"Mean distance in dimension %d is %f\" % (dimensions, sum_distance))\n",
    "    d[str(dimensions)] = sum_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.3332496908264852,\n",
       " '2': 0.5212556131792213,\n",
       " '3': 0.6616503043959507,\n",
       " '4': 0.7776623425731862,\n",
       " '10': 1.2673959751112913,\n",
       " '100': 4.075047152565091,\n",
       " '1000': 12.907583942040752,\n",
       " '1000000': 408.24854896803464}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Testing that it exists, now that I've compiled it from source!\n",
    "\n",
    "And I needed to compile Tensorflow because pre-packaged binaries emit AVX instructions\n",
    "which my old machine doesn't support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version =  2.3.0\n",
      "Keras version =  2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version = \", tf.__version__)\n",
    "print(\"Keras version = \", tf.keras.__version__)\n",
    "\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.image import imread\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# import mpl_toolkits.mplot3d.axes3d as p3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print (X_train_full.shape)\n",
    "print (X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000]        , y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge TPU\n",
    "\n",
    "Edge TPU devices don't run full TensorFlow, they only run tflite. For this, we need to create tflite models rather than normal TF models.\n",
    "\n",
    "[This page talks about creating TFlite models](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb).  The [TFLite converter class](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) is the one that creates the converted model. Let's save our model so that we can practice with it later.\n",
    "\n",
    "I need to save the model, and then run a converter, and then load them up on the Edge TPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphhyeosbg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphhyeosbg/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model = 'saved_models/fashion.h5'\n",
    "model.save(saved_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('saved_models/fashion_viki_test.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we need to convert the tflite models to edge TPU models. WTH, folks. This ought to be simpler than this. These instructions come from [the Coral page](https://coral.ai/docs/edgetpu/compiler/#system-requirements):\n",
    "\n",
    "```\n",
    "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get install edgetpu-compiler\n",
    "\n",
    "edgetpu-compiler model.tflite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, that doesn't work (were you expecting it to? You naive creature).\n",
    "\n",
    "For that, we have to quantize both the weights and the activation values. For that you have to [provide a representative dataset as this colab notebook points out](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb#scrollTo=w9ydAmHGHUZl&line=2&uniqifier=1). And of course, there [is some information on how to do this](https://www.tensorflow.org/lite/performance/post_training_quantization) but it is relatively slim on detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good lord. This is messy beyond belief. The [edgetpu-compiler itself crashes sometimes](https://github.com/google-coral/edgetpu/issues/168). No useful error messages, no information on how to provide it input, what format it is looking for. How the hell do people develop for this?\n",
    "\n",
    "[Someone else's view on how to get it working](https://towardsdatascience.com/solutions-to-issues-with-edge-tpu-32374310e732). This thing is a certified loony-town."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiujw_zaq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiujw_zaq/assets\n",
      "WARNING:absl:Please consider switching to the new converter by setting experimental_new_converter=True. The old converter (TOCO) is deprecated.\n"
     ]
    }
   ],
   "source": [
    "saved_model = 'saved_models/fashion.h5'\n",
    "model.save(saved_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "def representative_dataset_gen():\n",
    "    num_calibration_steps = 5\n",
    "    for p in range(num_calibration_steps):\n",
    "        # Get sample input data as a numpy array in a method of your choosing.\n",
    "        sample = X_train[p]\n",
    "        sample = tf.cast(sample, tf.float32)\n",
    "        yield [sample]\n",
    "\n",
    "\n",
    "# Set the representative dataset for the converter so we can quantize the activations\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "# Turn off MLIR\n",
    "converter.experimental_new_converter = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('saved_models/fashion_viki_test.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! Good heavens. This is incredibly poorly designed and thought out.\n",
    "\n",
    "```\n",
    "$ edgetpu_compiler -s fashion_viki_test.tflite \n",
    "Edge TPU Compiler version 14.1.317412892\n",
    "\n",
    "Model compiled successfully in 82 ms.\n",
    "\n",
    "Input model: fashion_viki_test.tflite\n",
    "Input size: 264.02KiB\n",
    "Output model: fashion_viki_test_edgetpu.tflite\n",
    "Output size: 332.53KiB\n",
    "On-chip memory used for caching model parameters: 290.75KiB\n",
    "On-chip memory remaining for caching model parameters: 7.57MiB\n",
    "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
    "Number of Edge TPU subgraphs: 1\n",
    "Total number of operations: 6\n",
    "Operation log: fashion_viki_test_edgetpu.log\n",
    "\n",
    "Operator                       Count      Status\n",
    "\n",
    "QUANTIZE                       2          Mapped to Edge TPU\n",
    "SOFTMAX                        1          Mapped to Edge TPU\n",
    "FULLY_CONNECTED                3          Mapped to Edge TPU\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "This person points out that [model size might be an issue as well](https://towardsdatascience.com/solutions-to-issues-with-edge-tpu-32374310e732).\n",
    "\n",
    "Opaque errors, unclear instructions, nonexistent toolchain.\n",
    "\n",
    "\n",
    "[Visit here to get Tensorflow lite support on the TPU](https://www.tensorflow.org/lite/guide/python).\n",
    "\n",
    "Trying to run the [TFlite examples on the Coral board](https://github.com/google-coral/tflite/tree/master/python/examples/classification) also fails rather horrendously with this error:\n",
    "```\n",
    "tflite/python/examples/classification$ python3 classify_image.py  \\\n",
    ">   --model models/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite \\\n",
    ">   --labels models/inat_bird_labels.txt \\\n",
    ">   --input images/parrot.jpg\n",
    "Traceback (most recent call last):\n",
    "  File \"classify_image.py\", line 122, in <module>\n",
    "    main()\n",
    "  File \"classify_image.py\", line 99, in main\n",
    "    interpreter = make_interpreter(args.model)\n",
    "  File \"classify_image.py\", line 73, in make_interpreter\n",
    "    {'device': device[0]} if device else {})\n",
    "  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 161, in load_delegate\n",
    "    delegate = Delegate(library, options)\n",
    "  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 90, in __init__\n",
    "    self._library = ctypes.pydll.LoadLibrary(library)\n",
    "  File \"/usr/lib/python3.5/ctypes/__init__.py\", line 425, in LoadLibrary\n",
    "    return self._dlltype(name)\n",
    "  File \"/usr/lib/python3.5/ctypes/__init__.py\", line 347, in __init__\n",
    "    self._handle = _dlopen(self._name, mode)\n",
    "OSError: libedgetpu.so.1: cannot open shared object file: No such file or directory\n",
    "Exception ignored in: <bound method Delegate.__del__ of <tflite_runtime.interpreter.Delegate object at 0xffff9ff92e80>>\n",
    "Traceback (most recent call last):\n",
    "  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 125, in __del__\n",
    "    if self._library is not None:\n",
    "AttributeError: 'Delegate' object has no attribute '_library'\n",
    "\n",
    "```\n",
    "\n",
    "And when you finally [find the shared object in this repository](https://github.com/google-coral/edgetpu/tree/master/libedgetpu/direct/aarch64), and try to [install it as it suggests](https://github.com/google-coral/edgetpu/blob/master/scripts/runtime/install.sh), you get the error\n",
    "```\n",
    "$ sudo scripts/runtime/install.sh\n",
    "[sudo] password for viki: \n",
    "Looks like you're using a Coral Dev Board. You should instead use Debian packages to manage Edge TPU software.\n",
    "\n",
    "```\n",
    "\n",
    "The library is available in one place, but not as libedgetpu.so.1:\n",
    "\n",
    "```\n",
    "viki@t2pu:/tmp/edgetpu$ find /usr/lib -name 'libedge*'\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu.so\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu_arm64.so\n",
    "\n",
    "\n",
    "viki@t2pu:/tmp/edgetpu$ dpkg -L libedgetpu\n",
    "/.\n",
    "/usr\n",
    "/usr/lib\n",
    "/usr/lib/aarch64-linux-gnu\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu_arm64.so\n",
    "/usr/share\n",
    "/usr/share/doc\n",
    "/usr/share/doc/libedgetpu\n",
    "/usr/share/doc/libedgetpu/changelog.Debian.gz\n",
    "/usr/share/doc/libedgetpu/copyright\n",
    "viki@t2pu:/tmp/edgetpu$ apt-cache show libedgetpu\n",
    "Package: libedgetpu\n",
    "Source: edgetpu-api\n",
    "Version: 5-2\n",
    "Installed-Size: 2324\n",
    "Maintainer: AIY Projects <support-aiyprojects@google.com>\n",
    "Architecture: arm64\n",
    "Description: Support library for Edge TPU\n",
    "Description-md5: db20ccbee0398559219c10588ef10b68\n",
    "Filename: pool/libedgetpu_5-2_arm64_21cebe814351c2fb24d590a521056716e8098cc3acdd95cca491c35f7ab57013.deb\n",
    "Priority: optional\n",
    "SHA256: 21cebe814351c2fb24d590a521056716e8098cc3acdd95cca491c35f7ab57013\n",
    "Section: misc\n",
    "Size: 688338\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "And the edgetpu_demo itself doesn't work:\n",
    "```\n",
    "$ edgetpu_demo --stream\n",
    "Press 'q' to quit.\n",
    "Press 'n' to switch between models.\n",
    "\n",
    "ERROR: Failed to retrieve TPU context.\n",
    "ERROR: Node number 0 (edgetpu-custom-op) failed to prepare.\n",
    "\n",
    "Failed in Tensor allocation, status_code: 1\n",
    "/usr/bin/edgetpu_demo: line 39: 10392 Aborted                 SERVER_INDEX_HTML=\"${TEST_DATA}/index.html\" edgetpu_detect_server --source \"${VIDEO_FILE}\" --model \"${TPU_MODEL_FILE},${CPU_MODEL_FILE}\" --labels \"${LABELS_FILE}\" --filter car --max_area 0.1 --color white --loop\n",
    "\n",
    "```\n",
    "\n",
    "This happens on both devices I have. \n",
    "\n",
    "After [updating the software with packages found on this page](https://coral.ai/software/#alternative-packages) I do have the .so.1 file, but now we have another failure:\n",
    "```\n",
    "root@t2pu:/tmp/tflite/python/examples/classification# python3 classify_image.py  --model models/mobilenet_v2_1.0_224_inat_bird_quant.tflite  --labels models/inat_bird_labels.txt  --input images/parrot.jpg\n",
    "Traceback (most recent call last):\n",
    "  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 161, in load_delegate\n",
    "    delegate = Delegate(library, options)\n",
    "  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 120, in __init__\n",
    "    raise ValueError(capture.message)\n",
    "ValueError\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"classify_image.py\", line 122, in <module>\n",
    "    main()\n",
    "  File \"classify_image.py\", line 99, in main\n",
    "    interpreter = make_interpreter(args.model)\n",
    "  File \"classify_image.py\", line 73, in make_interpreter\n",
    "    {'device': device[0]} if device else {})\n",
    "  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 164, in load_delegate\n",
    "    library, str(e)))\n",
    "ValueError: Failed to load delegate from libedgetpu.so.1\n",
    "\n",
    "```\n",
    "And some new files exist, but not the ones I need\n",
    "```\n",
    "# find /usr/lib -name '*edgetpu*'\n",
    "/usr/lib/python3/dist-packages/edgetpuvision\n",
    "/usr/lib/python3/dist-packages/edgetpuvision-1.0.egg-info\n",
    "/usr/lib/python3/dist-packages/edgetpu-2.14.1.egg-info\n",
    "/usr/lib/python3/dist-packages/edgetpu\n",
    "/usr/lib/python3/dist-packages/edgetpu/swig/_edgetpu_cpp_wrapper.cpython-36m-aarch64-linux-gnu.so\n",
    "/usr/lib/python3/dist-packages/edgetpu/swig/_edgetpu_cpp_wrapper.cpython-37m-aarch64-linux-gnu.so\n",
    "/usr/lib/python3/dist-packages/edgetpu/swig/_edgetpu_cpp_wrapper.cpython-35m-aarch64-linux-gnu.so\n",
    "/usr/lib/python3/dist-packages/edgetpu/swig/edgetpu_cpp_wrapper.py\n",
    "/usr/lib/python3/dist-packages/edgetpu/swig/__pycache__/edgetpu_cpp_wrapper.cpython-35.pyc\n",
    "/usr/lib/python3/dist-packages/edgetpu/swig/_edgetpu_cpp_wrapper.cpython-38-aarch64-linux-gnu.so\n",
    "/usr/lib/python3/dist-packages/edgetpu/basic/edgetpu_utils.py\n",
    "/usr/lib/python3/dist-packages/edgetpu/basic/__pycache__/edgetpu_utils.cpython-35.pyc\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu.so\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu.so.1\n",
    "/usr/lib/aarch64-linux-gnu/libedgetpu_arm64.so\n",
    "\n",
    "```\n",
    "\n",
    "I should update the entire system on the board when I get a chance. I should also load up an SD card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspberry PI\n",
    "\n",
    "Apparently, you can make [Tensorflow lite run on Raspberry PI following these easy instructions](https://www.tensorflow.org/lite/guide/build_rpi). I'm skeptical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other notes\n",
    "Links for Google Cloud Courses\n",
    "[The single video](https://www.coursera.org/lecture/gcp-fundamentals/why-choose-google-cloud-platform-vXwU1)\n",
    "and the full course:\n",
    "[You have to select single courses to view the content for free](https://www.coursera.org/specializations/gcp-architecture?action=enroll&authType=google&completeMode=existingCourseraAccount#courses)\n",
    "\n",
    "[These are someone's notes on this exam](https://medium.com/@sathishvj/notes-from-my-google-cloud-professional-cloud-architect-exam-bbc4299ac30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notes\n",
    "\n",
    "Python is an interesting language, and the list/tuple/nparray takes a while getting used to. Here's some lessons from what I have picked up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocating large amounts of memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.array([40000, 100000, 10029100, 202002], dtype=np.float32)\n",
    "s=bytearray(51200000*100)\n",
    "s=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting help on a specific method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

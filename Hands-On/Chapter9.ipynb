{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Testing out tensorflow, more than anything\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name=\"one\")\n",
    "y = tf.Variable(3, name=\"two\")\n",
    "z = x*x*y + y + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we use the variables above\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "sess.run(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = z.eval()\n",
    "    print (result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Doing linear regression with TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(download_if_missing=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63ca216d1d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtheta_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtheta_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print (theta_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(download_if_missing=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': 'California housing dataset.\\n\\nThe original database is available from StatLib\\n\\n    http://lib.stat.cmu.edu/datasets/\\n\\nThe data contains 20,640 observations on 9 variables.\\n\\nThis dataset contains the average house value as target variable\\nand the following input variables (features): average income,\\nhousing average age, average rooms, average bedrooms, population,\\naverage occupation, latitude, and longitude in that order.\\n\\nReferences\\n----------\\n\\nPace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\nStatistics and Probability Letters, 33 (1997) 291-297.\\n\\n'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "m,n = housing.data.shape\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "Xt = tf.transpose(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(Xt, X)), Xt), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.3280170e-01  1.7330862e-03  1.4024429e-04 -1.6960822e-03\n",
      "   4.9653235e-03  2.6645776e-07 -2.0582816e-05  8.0592949e-03\n",
      "   9.4271358e-03]\n",
      " [ 1.7292782e-03  3.3596345e-05  3.6661200e-07 -3.5115801e-05\n",
      "   1.5580961e-04  7.2289746e-10 -1.4578103e-07  2.3929504e-05\n",
      "   2.2608423e-05]\n",
      " [ 1.4008376e-04  3.6694277e-07  3.7985012e-07  2.2102078e-07\n",
      "  -4.9968071e-07  1.2947088e-09 -1.8697900e-08  1.5904914e-06\n",
      "   1.7688019e-06]\n",
      " [-1.6910866e-03 -3.5112891e-05  2.2157481e-07  6.6045650e-05\n",
      "  -2.9091924e-04  2.0295519e-09  1.1897595e-07 -2.5522480e-05\n",
      "  -2.2474647e-05]\n",
      " [ 4.9407473e-03  1.5578012e-04 -5.0305511e-07 -2.9089939e-04\n",
      "   1.5091239e-03 -1.7626423e-09 -5.0066774e-07  8.6477310e-05\n",
      "   7.2613147e-05]\n",
      " [ 2.6473597e-07  7.2088191e-10  1.2944725e-09  2.0308690e-09\n",
      "  -1.7621378e-09  4.2999104e-11 -3.5454825e-10  6.6607453e-09\n",
      "   5.1119375e-09]\n",
      " [-2.0562160e-05 -1.4583246e-07 -1.8698287e-08  1.1905893e-07\n",
      "  -5.0115784e-07 -3.5458267e-10  4.5291179e-07 -2.5852205e-07\n",
      "  -2.4999403e-07]\n",
      " [ 8.0525242e-03  2.3952663e-05  1.5908820e-06 -2.5557980e-05\n",
      "   8.6679000e-05  6.6748935e-09 -2.5855658e-07  9.9212790e-05\n",
      "   9.7775293e-05]\n",
      " [ 9.4249323e-03  2.2647082e-05  1.7702403e-06 -2.2527036e-05\n",
      "   7.2879659e-05  5.1306071e-09 -2.5017408e-07  9.7830620e-05\n",
      "   1.0883486e-04]]\n"
     ]
    }
   ],
   "source": [
    "theta\n",
    "intermediate = tf.matrix_inverse(tf.matmul(Xt, X))\n",
    "with tf.Session() as sess:\n",
    "    print(intermediate.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print (theta_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(housing_data_plus_bias)\n",
    "scaled_housing_data = scaler.transform(housing_data_plus_bias)\n",
    "\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , MSE =  7.3372774\n",
      "Epoch  100 , MSE =  7.230086\n",
      "Epoch  200 , MSE =  7.1278553\n",
      "Epoch  300 , MSE =  7.0303607\n",
      "Epoch  400 , MSE =  6.937358\n",
      "Epoch  500 , MSE =  6.8486342\n",
      "Epoch  600 , MSE =  6.7639837\n",
      "Epoch  700 , MSE =  6.6832075\n",
      "Epoch  800 , MSE =  6.606114\n",
      "Epoch  900 , MSE =  6.532536\n",
      "Epoch  1000 , MSE =  6.4623046\n",
      "Epoch  1100 , MSE =  6.3952537\n",
      "Epoch  1200 , MSE =  6.3312426\n",
      "Epoch  1300 , MSE =  6.2701106\n",
      "Epoch  1400 , MSE =  6.2117352\n",
      "Epoch  1500 , MSE =  6.155979\n",
      "Epoch  1600 , MSE =  6.102724\n",
      "Epoch  1700 , MSE =  6.0518456\n",
      "Epoch  1800 , MSE =  6.003243\n",
      "Epoch  1900 , MSE =  5.9567976\n",
      "Epoch  2000 , MSE =  5.912422\n",
      "Epoch  2100 , MSE =  5.8700066\n",
      "Epoch  2200 , MSE =  5.8294697\n",
      "Epoch  2300 , MSE =  5.7907214\n",
      "Epoch  2400 , MSE =  5.7536798\n",
      "Epoch  2500 , MSE =  5.7182627\n",
      "Epoch  2600 , MSE =  5.6843977\n",
      "Epoch  2700 , MSE =  5.652016\n",
      "Epoch  2800 , MSE =  5.621048\n",
      "Epoch  2900 , MSE =  5.5914273\n",
      "Epoch  3000 , MSE =  5.5630927\n",
      "Epoch  3100 , MSE =  5.535985\n",
      "Epoch  3200 , MSE =  5.5100603\n",
      "Epoch  3300 , MSE =  5.4852443\n",
      "Epoch  3400 , MSE =  5.4615006\n",
      "Epoch  3500 , MSE =  5.4387794\n",
      "Epoch  3600 , MSE =  5.4170322\n",
      "Epoch  3700 , MSE =  5.396214\n",
      "Epoch  3800 , MSE =  5.376288\n",
      "Epoch  3900 , MSE =  5.3572097\n",
      "Epoch  4000 , MSE =  5.3389435\n",
      "Epoch  4100 , MSE =  5.3214517\n",
      "Epoch  4200 , MSE =  5.3047\n",
      "Epoch  4300 , MSE =  5.2886605\n",
      "Epoch  4400 , MSE =  5.2732916\n",
      "Epoch  4500 , MSE =  5.2585735\n",
      "Epoch  4600 , MSE =  5.2444706\n",
      "Epoch  4700 , MSE =  5.2309585\n",
      "Epoch  4800 , MSE =  5.218008\n",
      "Epoch  4900 , MSE =  5.2056007\n",
      "Epoch  5000 , MSE =  5.193709\n",
      "Epoch  5100 , MSE =  5.182312\n",
      "Epoch  5200 , MSE =  5.171384\n",
      "Epoch  5300 , MSE =  5.1609073\n",
      "Epoch  5400 , MSE =  5.150865\n",
      "Epoch  5500 , MSE =  5.1412344\n",
      "Epoch  5600 , MSE =  5.1319966\n",
      "Epoch  5700 , MSE =  5.123136\n",
      "Epoch  5800 , MSE =  5.1146417\n",
      "Epoch  5900 , MSE =  5.1064878\n",
      "Epoch  6000 , MSE =  5.0986657\n",
      "Epoch  6100 , MSE =  5.091159\n",
      "Epoch  6200 , MSE =  5.0839577\n",
      "Epoch  6300 , MSE =  5.0770416\n",
      "Epoch  6400 , MSE =  5.0704074\n",
      "Epoch  6500 , MSE =  5.0640354\n",
      "Epoch  6600 , MSE =  5.0579205\n",
      "Epoch  6700 , MSE =  5.052046\n",
      "Epoch  6800 , MSE =  5.04641\n",
      "Epoch  6900 , MSE =  5.0409894\n",
      "Epoch  7000 , MSE =  5.0357866\n",
      "Epoch  7100 , MSE =  5.0307856\n",
      "Epoch  7200 , MSE =  5.0259805\n",
      "Epoch  7300 , MSE =  5.0213623\n",
      "Epoch  7400 , MSE =  5.016925\n",
      "Epoch  7500 , MSE =  5.0126605\n",
      "Epoch  7600 , MSE =  5.0085588\n",
      "Epoch  7700 , MSE =  5.004614\n",
      "Epoch  7800 , MSE =  5.0008235\n",
      "Epoch  7900 , MSE =  4.997175\n",
      "Epoch  8000 , MSE =  4.9936657\n",
      "Epoch  8100 , MSE =  4.9902897\n",
      "Epoch  8200 , MSE =  4.9870405\n",
      "Epoch  8300 , MSE =  4.9839115\n",
      "Epoch  8400 , MSE =  4.980903\n",
      "Epoch  8500 , MSE =  4.9780064\n",
      "Epoch  8600 , MSE =  4.975214\n",
      "Epoch  8700 , MSE =  4.972528\n",
      "Epoch  8800 , MSE =  4.9699388\n",
      "Epoch  8900 , MSE =  4.9674435\n",
      "Epoch  9000 , MSE =  4.9650383\n",
      "Epoch  9100 , MSE =  4.962721\n",
      "Epoch  9200 , MSE =  4.960489\n",
      "Epoch  9300 , MSE =  4.9583354\n",
      "Epoch  9400 , MSE =  4.9562573\n",
      "Epoch  9500 , MSE =  4.9542537\n",
      "Epoch  9600 , MSE =  4.95232\n",
      "Epoch  9700 , MSE =  4.9504566\n",
      "Epoch  9800 , MSE =  4.9486556\n",
      "Epoch  9900 , MSE =  4.9469175\n",
      "[[-0.6749339 ]\n",
      " [ 0.8882686 ]\n",
      " [ 0.09317137]\n",
      " [-0.51764417]\n",
      " [ 0.45912635]\n",
      " [ 0.02931158]\n",
      " [-0.00686855]\n",
      " [ 0.10138819]\n",
      " [ 0.09028768]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually computing gradients\n",
    "n_epochs = 10000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "X = tf.constant(scaled_housing_data, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1, 1), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf. reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch \", epoch, \", MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , MSE =  8.48195\n",
      "Epoch  100 , MSE =  8.254466\n",
      "Epoch  200 , MSE =  8.042218\n",
      "Epoch  300 , MSE =  7.8441586\n",
      "Epoch  400 , MSE =  7.659307\n",
      "Epoch  500 , MSE =  7.4867535\n",
      "Epoch  600 , MSE =  7.3256497\n",
      "Epoch  700 , MSE =  7.1752157\n",
      "Epoch  800 , MSE =  7.0347066\n",
      "Epoch  900 , MSE =  6.903458\n",
      "Epoch  1000 , MSE =  6.780829\n",
      "Epoch  1100 , MSE =  6.6662335\n",
      "Epoch  1200 , MSE =  6.5591207\n",
      "Epoch  1300 , MSE =  6.4589834\n",
      "Epoch  1400 , MSE =  6.3653493\n",
      "Epoch  1500 , MSE =  6.277785\n",
      "Epoch  1600 , MSE =  6.1958666\n",
      "Epoch  1700 , MSE =  6.1192217\n",
      "Epoch  1800 , MSE =  6.047494\n",
      "Epoch  1900 , MSE =  5.9803524\n",
      "Epoch  2000 , MSE =  5.9174905\n",
      "Epoch  2100 , MSE =  5.858621\n",
      "Epoch  2200 , MSE =  5.8034787\n",
      "Epoch  2300 , MSE =  5.7518163\n",
      "Epoch  2400 , MSE =  5.703396\n",
      "Epoch  2500 , MSE =  5.6580095\n",
      "Epoch  2600 , MSE =  5.615456\n",
      "Epoch  2700 , MSE =  5.5755453\n",
      "Epoch  2800 , MSE =  5.538107\n",
      "Epoch  2900 , MSE =  5.50298\n",
      "Epoch  3000 , MSE =  5.4700084\n",
      "Epoch  3100 , MSE =  5.4390526\n",
      "Epoch  3200 , MSE =  5.4099846\n",
      "Epoch  3300 , MSE =  5.3826795\n",
      "Epoch  3400 , MSE =  5.3570194\n",
      "Epoch  3500 , MSE =  5.332907\n",
      "Epoch  3600 , MSE =  5.310233\n",
      "Epoch  3700 , MSE =  5.288917\n",
      "Epoch  3800 , MSE =  5.2688594\n",
      "Epoch  3900 , MSE =  5.249985\n",
      "Epoch  4000 , MSE =  5.2322197\n",
      "Epoch  4100 , MSE =  5.2154975\n",
      "Epoch  4200 , MSE =  5.1997433\n",
      "Epoch  4300 , MSE =  5.1849027\n",
      "Epoch  4400 , MSE =  5.170916\n",
      "Epoch  4500 , MSE =  5.1577277\n",
      "Epoch  4600 , MSE =  5.1452904\n",
      "Epoch  4700 , MSE =  5.1335607\n",
      "Epoch  4800 , MSE =  5.1224923\n",
      "Epoch  4900 , MSE =  5.1120386\n",
      "Epoch  5000 , MSE =  5.1021733\n",
      "Epoch  5100 , MSE =  5.0928516\n",
      "Epoch  5200 , MSE =  5.0840373\n",
      "Epoch  5300 , MSE =  5.075713\n",
      "Epoch  5400 , MSE =  5.067839\n",
      "Epoch  5500 , MSE =  5.0603867\n",
      "Epoch  5600 , MSE =  5.053335\n",
      "Epoch  5700 , MSE =  5.04666\n",
      "Epoch  5800 , MSE =  5.0403395\n",
      "Epoch  5900 , MSE =  5.0343533\n",
      "Epoch  6000 , MSE =  5.028676\n",
      "Epoch  6100 , MSE =  5.0232944\n",
      "Epoch  6200 , MSE =  5.01819\n",
      "Epoch  6300 , MSE =  5.013348\n",
      "Epoch  6400 , MSE =  5.008749\n",
      "Epoch  6500 , MSE =  5.0043845\n",
      "Epoch  6600 , MSE =  5.000234\n",
      "Epoch  6700 , MSE =  4.996296\n",
      "Epoch  6800 , MSE =  4.9925466\n",
      "Epoch  6900 , MSE =  4.9889827\n",
      "Epoch  7000 , MSE =  4.98559\n",
      "Epoch  7100 , MSE =  4.9823565\n",
      "Epoch  7200 , MSE =  4.9792833\n",
      "Epoch  7300 , MSE =  4.976352\n",
      "Epoch  7400 , MSE =  4.973558\n",
      "Epoch  7500 , MSE =  4.970895\n",
      "Epoch  7600 , MSE =  4.968354\n",
      "Epoch  7700 , MSE =  4.9659243\n",
      "Epoch  7800 , MSE =  4.9636045\n",
      "Epoch  7900 , MSE =  4.9613934\n",
      "Epoch  8000 , MSE =  4.959277\n",
      "Epoch  8100 , MSE =  4.9572525\n",
      "Epoch  8200 , MSE =  4.9553165\n",
      "Epoch  8300 , MSE =  4.953464\n",
      "Epoch  8400 , MSE =  4.9516873\n",
      "Epoch  8500 , MSE =  4.9499903\n",
      "Epoch  8600 , MSE =  4.9483585\n",
      "Epoch  8700 , MSE =  4.946794\n",
      "Epoch  8800 , MSE =  4.945294\n",
      "Epoch  8900 , MSE =  4.943853\n",
      "Epoch  9000 , MSE =  4.942471\n",
      "Epoch  9100 , MSE =  4.941139\n",
      "Epoch  9200 , MSE =  4.93986\n",
      "Epoch  9300 , MSE =  4.9386315\n",
      "Epoch  9400 , MSE =  4.937448\n",
      "Epoch  9500 , MSE =  4.9363084\n",
      "Epoch  9600 , MSE =  4.9352083\n",
      "Epoch  9700 , MSE =  4.93415\n",
      "Epoch  9800 , MSE =  4.9331284\n",
      "Epoch  9900 , MSE =  4.932142\n",
      "[[-0.5018468 ]\n",
      " [ 0.898482  ]\n",
      " [ 0.18980524]\n",
      " [-0.40576878]\n",
      " [ 0.34216616]\n",
      " [ 0.07034998]\n",
      " [-0.01067769]\n",
      " [ 0.11896352]\n",
      " [ 0.09728553]]\n"
     ]
    }
   ],
   "source": [
    "# The same code as above using auto-diff gradients which automatically compute\n",
    "# the gradients of an unknown operation\n",
    "\n",
    "n_epochs = 10000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "X = tf.constant(scaled_housing_data, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1, 1), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch \", epoch, \", MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7486987\n",
      "4.9461303\n",
      "4.903606\n",
      "4.879715\n",
      "4.861981\n",
      "4.848603\n",
      "4.838457\n",
      "4.8307214\n",
      "4.8247957\n",
      "4.8202343\n",
      "[[-0.31000543]\n",
      " [ 0.8971107 ]\n",
      " [ 0.15766022]\n",
      " [-0.34393546]\n",
      " [ 0.34893757]\n",
      " [ 0.00877511]\n",
      " [-0.04405664]\n",
      " [-0.5528744 ]\n",
      " [-0.5290092 ]]\n"
     ]
    }
   ],
   "source": [
    "# And we can create the gradients automatically and also run gradient descent by\n",
    "# running the GradientDescentOptimizer\n",
    "\n",
    "from tensorflow.train import GradientDescentOptimizer\n",
    "from datetime import datetime\n",
    "\n",
    "# For tensorboard\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"/tmp/{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(scaled_housing_data, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1, 1), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "mse_summary=tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            summary_str = mse_summary.eval()\n",
    "            step = epoch\n",
    "            file_writer.add_summary(summary_str, step)\n",
    "            print(mse.eval())\n",
    "\n",
    "            # This was what we did for printing it out to stdout.\n",
    "            #print (\"Epoch \", epoch, \", MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "\n",
    "    # And we can save this session once we are done.\n",
    "    saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders are used to fill data at run-time, and they are used to keep spots\n",
    "# free for computation that can be filled up later.\n",
    "\n",
    "# None signifies that this axes is unspecified.\n",
    "A = tf.placeholder(tf.float32, shape=(None, None, None, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_5:0' shape=(?, ?, ?, 3) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[11. 12.  9.]\n",
      "   [ 6.  7.  8.]]\n",
      "\n",
      "  [[11. 12.  9.]\n",
      "   [ 6.  7.  8.]]]\n",
      "\n",
      "\n",
      " [[[11. 12.  9.]\n",
      "   [ 6.  7.  8.]]\n",
      "\n",
      "  [[11. 12.  9.]\n",
      "   [ 6.  7.  8.]]]]\n"
     ]
    }
   ],
   "source": [
    "B = A + 5\n",
    "\n",
    "with tf.Session() as s:\n",
    "    B_1 = B.eval(feed_dict = {A: [[[[6 ,7, 4],[1, 2, 3]], [[6 ,7, 4],[1, 2, 3]]], [[[6 ,7, 4],[1, 2, 3]], [[6 ,7, 4],[1, 2, 3]]]]})\n",
    "    print (B_1)\n",
    "    \n",
    "    #B_2 = B.eval(feed_dict = {A: [[],[], [1, 3, 4], [2, 3, 4]]})\n",
    "    #print (B_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-b4ceca5c74fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "housing.data.shape\n",
    "housing.target.shape\n",
    "\n",
    "sample_size=10000\n",
    "#p = [i for i in range(sample_size)]\n",
    "#print(p)\n",
    "\n",
    "X = [[1, 2, 3 ], [4, 5, 6], [7, 8, 9]]\n",
    "print(X[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using placeholders, we can specify mini-batch gradient descent by sampling values into\n",
    "# the matrix X and the values y.\n",
    "\n",
    "from tensorflow.train import GradientDescentOptimizer\n",
    "\n",
    "n_epochs = 4000\n",
    "learning_rate = 0.001\n",
    "sample_size=10000\n",
    "# 8 features, and 1 intercept\n",
    "feature_size=8\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(sample_size, 9), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(sample_size, 1), name=\"y\")\n",
    "\n",
    "\n",
    "X = tf.constant(scaled_housing_data, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "# 8 features, and 1 intercept\n",
    "theta = tf.Variable(tf.random_uniform([feature_size+1, 1], -1, 1), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Get a random distribution of sample_size rows from 1 to 20640\n",
    "        indices = [i for i in range(sample_size)]\n",
    "\n",
    "        # pick the rows of the housing_data matrix\n",
    "        X\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch \", epoch, \", MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
